{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f5bfe6",
   "metadata": {},
   "source": [
    "## TrendsMarketPlace\n",
    "## Business Use Case\n",
    "# Enhancing E-Commerce Conversion Rates Through Predictive Modeling\n",
    "\n",
    "#### Description:\n",
    "In the competitive e-commerce space, improving conversion rates is a critical metric for success. This business use case involves leveraging the \"Online Shoppers Intention Dataset\" to develop predictive models that identify visitors with a high likelihood of making a purchase or abandoning the website.\n",
    "\n",
    "The insights derived from these models can be utilized to:\n",
    "\n",
    "1. Personalize Customer Experience: Identify high-intent buyers in real-time and offer targeted promotions or assistance.\n",
    "2. Reduce Cart Abandonment: Proactively engage visitors likely to leave the site without completing a transaction through tailored incentives.\n",
    "3. Improve Marketing ROI: Optimize ad spending by focusing on segments with higher purchasing intent.\n",
    "4. Enhance Operational Efficiency: Provide data-driven insights for better decision-making in marketing, customer service, and website design.\n",
    "\n",
    "#### Impact:\n",
    "By implementing these predictive models, e-commerce platforms can achieve:\n",
    "\n",
    "1. Increased revenue by boosting purchase conversion rates.\n",
    "2. Reduced operational costs by targeting the right customers at the right time.\n",
    "3. Enhanced customer satisfaction and retention through personalized interventions.\n",
    "\n",
    "\n",
    "##### Team Members: Jacob Battles | Garrett Kierzek | Abdihakim Bashe | Divyansh Sen | Utkarsh Joshi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff7bf5",
   "metadata": {},
   "source": [
    "#### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660342c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "import pymysql as sql\n",
    "\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c470ce3",
   "metadata": {},
   "source": [
    "#### Connecting to MYSQL database\n",
    "Database: TrendMarketplace\n",
    "\n",
    "Table: online_shoppers_intention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0eaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": \"root\",\n",
    "    \"database\": \"trendmarketplace\",\n",
    "    \"password\": \"Mysqlsystem1!\"\n",
    "}\n",
    "\n",
    "# Load data from the database\n",
    "def load_data(query=\"SELECT * FROM online_shoppers_intention;\"):\n",
    "    connection = sql.connect(**db_config)\n",
    "    try:\n",
    "        df = pd.read_sql(query, con=connection)\n",
    "    finally:\n",
    "        connection.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3de92",
   "metadata": {},
   "source": [
    "#### Preprocess Data\n",
    " 1. Remove Nulls\n",
    " 2. Implementing Standardscaler and Onehotencoding for Categorical and Numerical Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a40105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Handle missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop('Revenue', axis=1)\n",
    "    y = df['Revenue']\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # Preprocessing pipelines\n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Combine preprocessors\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, numerical_cols),\n",
    "            ('cat', cat_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "    return X, y, preprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d69e1",
   "metadata": {},
   "source": [
    "### Implementing Optuna library for optimizing hyperparameters in the ML model.  \n",
    "#### Models:\n",
    "1. RandomForest\n",
    "2. logisticRegression\n",
    "3. SVM\n",
    "4. Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee85ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model functions with Optuna integration\n",
    "def optimize_random_forest(trial, X, y, preprocessor):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300, step=50)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 30, step=5)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=1)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_logistic_regression(trial, X, y, preprocessor):\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-4, 1e2)\n",
    "    solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\"])\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l2\"])\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        penalty=penalty,\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_svm(trial, X, y, preprocessor):\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-4, 1e2)\n",
    "    gamma = trial.suggest_loguniform(\"gamma\", 1e-4, 1e-1)\n",
    "\n",
    "    model = SVC(\n",
    "        C=C,\n",
    "        gamma=gamma,\n",
    "        kernel=\"rbf\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "    return np.mean(scores)\n",
    "\n",
    "def optimize_mlp(trial, X, y, preprocessor):\n",
    "    hidden_layer_sizes = trial.suggest_int(\"hidden_layer_sizes\", 50, 200, step=50)\n",
    "    alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(hidden_layer_sizes,),\n",
    "        alpha=alpha,\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af7c6f",
   "metadata": {},
   "source": [
    "### Comparison between Results obtained with and without Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2fbe0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating models before optimization...\n",
      "Random Forest Accuracy: 0.9012 (+/- 0.0050)\n",
      "Logistic Regression Accuracy: 0.8843 (+/- 0.0036)\n",
      "Support Vector Machine Accuracy: 0.8932 (+/- 0.0053)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 15:50:40,439] A new study created in memory with name: no-name-dadafa23-e6a3-488e-b295-1f434f12ce49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.8821 (+/- 0.0028)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Optimizing models using Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 15:50:51,563] Trial 0 finished with value: 0.9012165450121655 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 3}. Best is trial 0 with value: 0.9012165450121655.\n",
      "[I 2024-12-04 15:50:53,211] Trial 1 finished with value: 0.8927818329278183 and parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 0 with value: 0.9012165450121655.\n",
      "[I 2024-12-04 15:51:03,409] Trial 2 finished with value: 0.9018653690186538 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 2 with value: 0.9018653690186538.\n",
      "[I 2024-12-04 15:51:15,941] Trial 3 finished with value: 0.902514193025142 and parameters: {'n_estimators': 250, 'max_depth': 30, 'min_samples_split': 5}. Best is trial 3 with value: 0.902514193025142.\n",
      "[I 2024-12-04 15:51:20,377] Trial 4 finished with value: 0.9044606650446066 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:51:24,458] Trial 5 finished with value: 0.9030008110300081 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 7}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:51:34,319] Trial 6 finished with value: 0.9023519870235198 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 4}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:51:38,484] Trial 7 finished with value: 0.8904298459042985 and parameters: {'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:51:40,207] Trial 8 finished with value: 0.8927818329278183 and parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:51:47,863] Trial 9 finished with value: 0.9 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 3}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:01,629] Trial 10 finished with value: 0.902757502027575 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:06,399] Trial 11 finished with value: 0.9024330900243308 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:10,503] Trial 12 finished with value: 0.9030008110300081 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 7}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:14,572] Trial 13 finished with value: 0.903081914030819 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:19,419] Trial 14 finished with value: 0.9041362530413626 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 10}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:22,076] Trial 15 finished with value: 0.9041362530413626 and parameters: {'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 10}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:30,391] Trial 16 finished with value: 0.9039740470397405 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:35,892] Trial 17 finished with value: 0.9017031630170317 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:38,606] Trial 18 finished with value: 0.9014598540145986 and parameters: {'n_estimators': 50, 'max_depth': 15, 'min_samples_split': 8}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:46,171] Trial 19 finished with value: 0.902433090024331 and parameters: {'n_estimators': 150, 'max_depth': 25, 'min_samples_split': 5}. Best is trial 4 with value: 0.9044606650446066.\n",
      "[I 2024-12-04 15:52:46,171] A new study created in memory with name: no-name-ddb32bf7-9206-44b0-aabe-cc0f05b59a10\n",
      "[I 2024-12-04 15:52:46,475] Trial 0 finished with value: 0.8685320356853203 and parameters: {'C': 0.0006268856826594517, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 0 with value: 0.8685320356853203.\n",
      "[I 2024-12-04 15:52:47,183] Trial 1 finished with value: 0.8844282238442822 and parameters: {'C': 1.256672137868152, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:47,482] Trial 2 finished with value: 0.881589618815896 and parameters: {'C': 0.0114814787647926, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:47,821] Trial 3 finished with value: 0.8787510137875101 and parameters: {'C': 0.0058798946228987995, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:48,210] Trial 4 finished with value: 0.881589618815896 and parameters: {'C': 0.01605440297510177, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:48,534] Trial 5 finished with value: 0.8834549878345499 and parameters: {'C': 0.031534427807511194, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:48,816] Trial 6 finished with value: 0.846147607461476 and parameters: {'C': 0.00015000854738232266, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:49,203] Trial 7 finished with value: 0.8844282238442822 and parameters: {'C': 17.138031412113882, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:50,031] Trial 8 finished with value: 0.8844282238442822 and parameters: {'C': 8.010108143068036, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:50,285] Trial 9 finished with value: 0.8700729927007298 and parameters: {'C': 0.0007942859812897788, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:51,000] Trial 10 finished with value: 0.8844282238442822 and parameters: {'C': 0.7270629378734617, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:51,388] Trial 11 finished with value: 0.8844282238442822 and parameters: {'C': 51.264425728460054, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:52,061] Trial 12 finished with value: 0.8844282238442822 and parameters: {'C': 0.6558803835905667, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:52,466] Trial 13 finished with value: 0.8844282238442822 and parameters: {'C': 4.215524544835483, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:52,852] Trial 14 finished with value: 0.8844282238442822 and parameters: {'C': 70.93685938533831, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:53,522] Trial 15 finished with value: 0.8844282238442822 and parameters: {'C': 0.6287983053050393, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:54,409] Trial 16 finished with value: 0.8844282238442822 and parameters: {'C': 6.6946235528598494, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:54,775] Trial 17 finished with value: 0.884022708840227 and parameters: {'C': 0.1143452875774588, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:55,604] Trial 18 finished with value: 0.8844282238442822 and parameters: {'C': 2.064533227051458, 'solver': 'lbfgs', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:56,116] Trial 19 finished with value: 0.8844282238442822 and parameters: {'C': 21.46796372079976, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 1 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:52:56,117] A new study created in memory with name: no-name-fd70215e-b6ca-459e-8999-02defd32e76a\n",
      "[I 2024-12-04 15:53:08,649] Trial 0 finished with value: 0.8491484184914843 and parameters: {'C': 0.15356935166208982, 'gamma': 0.0004592829234034454}. Best is trial 0 with value: 0.8491484184914843.\n",
      "[I 2024-12-04 15:53:19,979] Trial 1 finished with value: 0.8452554744525548 and parameters: {'C': 0.0004944916695783785, 'gamma': 0.0019830687725030374}. Best is trial 0 with value: 0.8491484184914843.\n",
      "[I 2024-12-04 15:53:30,694] Trial 2 finished with value: 0.8844282238442822 and parameters: {'C': 4.393136610785162, 'gamma': 0.0005250803560192693}. Best is trial 2 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:53:43,236] Trial 3 finished with value: 0.8642335766423358 and parameters: {'C': 0.010834739045303726, 'gamma': 0.050513356803381385}. Best is trial 2 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:53:54,457] Trial 4 finished with value: 0.8452554744525548 and parameters: {'C': 0.00011766910055039219, 'gamma': 0.08471063547502787}. Best is trial 2 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:54:06,482] Trial 5 finished with value: 0.8452554744525548 and parameters: {'C': 0.005692832481383713, 'gamma': 0.009001001092699223}. Best is trial 2 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:54:17,698] Trial 6 finished with value: 0.8786699107866991 and parameters: {'C': 0.4236966950641103, 'gamma': 0.0012489850247727327}. Best is trial 2 with value: 0.8844282238442822.\n",
      "[I 2024-12-04 15:54:30,121] Trial 7 finished with value: 0.8894566098945662 and parameters: {'C': 45.99765451126222, 'gamma': 0.0009669170870699751}. Best is trial 7 with value: 0.8894566098945662.\n",
      "[I 2024-12-04 15:54:42,392] Trial 8 finished with value: 0.8746958637469586 and parameters: {'C': 0.021299428572952906, 'gamma': 0.052875096195875326}. Best is trial 7 with value: 0.8894566098945662.\n",
      "[I 2024-12-04 15:54:54,261] Trial 9 finished with value: 0.8458231954582318 and parameters: {'C': 0.18865930503677805, 'gamma': 0.00016565596820554011}. Best is trial 7 with value: 0.8894566098945662.\n",
      "[I 2024-12-04 15:55:11,751] Trial 10 finished with value: 0.8927007299270073 and parameters: {'C': 99.49196895589162, 'gamma': 0.009425405910114851}. Best is trial 10 with value: 0.8927007299270073.\n",
      "[I 2024-12-04 15:55:30,004] Trial 11 finished with value: 0.8915652879156528 and parameters: {'C': 92.5796829431017, 'gamma': 0.011876108086330314}. Best is trial 10 with value: 0.8927007299270073.\n",
      "[I 2024-12-04 15:55:46,688] Trial 12 finished with value: 0.8932684509326846 and parameters: {'C': 84.8174788658807, 'gamma': 0.00923743334276576}. Best is trial 12 with value: 0.8932684509326846.\n",
      "[I 2024-12-04 15:55:58,031] Trial 13 finished with value: 0.8909975669099757 and parameters: {'C': 5.014356894351165, 'gamma': 0.00655827222755215}. Best is trial 12 with value: 0.8932684509326846.\n",
      "[I 2024-12-04 15:56:10,813] Trial 14 finished with value: 0.8942416869424168 and parameters: {'C': 9.076247929028378, 'gamma': 0.02352449227235009}. Best is trial 14 with value: 0.8942416869424168.\n",
      "[I 2024-12-04 15:56:23,335] Trial 15 finished with value: 0.894728304947283 and parameters: {'C': 6.121723427923262, 'gamma': 0.02350387225533512}. Best is trial 15 with value: 0.894728304947283.\n",
      "[I 2024-12-04 15:56:35,285] Trial 16 finished with value: 0.8939172749391728 and parameters: {'C': 3.782897969773196, 'gamma': 0.027099525896441403}. Best is trial 15 with value: 0.894728304947283.\n",
      "[I 2024-12-04 15:56:46,778] Trial 17 finished with value: 0.8927007299270073 and parameters: {'C': 1.6588681092587643, 'gamma': 0.02263131942456965}. Best is trial 15 with value: 0.894728304947283.\n",
      "[I 2024-12-04 15:56:58,679] Trial 18 finished with value: 0.8910786699107867 and parameters: {'C': 19.312165196458633, 'gamma': 0.003651357174379489}. Best is trial 15 with value: 0.894728304947283.\n",
      "[I 2024-12-04 15:57:10,064] Trial 19 finished with value: 0.8911597729115976 and parameters: {'C': 0.7416844356229428, 'gamma': 0.022078649282713424}. Best is trial 15 with value: 0.894728304947283.\n",
      "[I 2024-12-04 15:57:10,065] A new study created in memory with name: no-name-2ea0f562-f877-4bb3-b4ad-9ad683662cf5\n",
      "[I 2024-12-04 16:00:45,645] Trial 0 finished with value: 0.8936739659367395 and parameters: {'hidden_layer_sizes': 50, 'alpha': 0.009323065441390633}. Best is trial 0 with value: 0.8936739659367395.\n",
      "[I 2024-12-04 16:05:57,347] Trial 1 finished with value: 0.883698296836983 and parameters: {'hidden_layer_sizes': 150, 'alpha': 0.00014396941773929292}. Best is trial 0 with value: 0.8936739659367395.\n",
      "[I 2024-12-04 16:11:29,302] Trial 2 finished with value: 0.8827250608272506 and parameters: {'hidden_layer_sizes': 200, 'alpha': 0.0037484899297666064}. Best is trial 0 with value: 0.8936739659367395.\n",
      "[I 2024-12-04 16:14:49,112] Trial 3 finished with value: 0.8897810218978103 and parameters: {'hidden_layer_sizes': 50, 'alpha': 0.00017570392760067114}. Best is trial 0 with value: 0.8936739659367395.\n",
      "[I 2024-12-04 16:16:40,926] Trial 4 finished with value: 0.8978102189781021 and parameters: {'hidden_layer_sizes': 150, 'alpha': 0.09626216235443985}. Best is trial 4 with value: 0.8978102189781021.\n",
      "[I 2024-12-04 16:20:42,350] Trial 5 finished with value: 0.8905109489051094 and parameters: {'hidden_layer_sizes': 50, 'alpha': 0.000628928628838167}. Best is trial 4 with value: 0.8978102189781021.\n",
      "[I 2024-12-04 16:24:37,303] Trial 6 finished with value: 0.8922952149229522 and parameters: {'hidden_layer_sizes': 200, 'alpha': 0.033083001442182104}. Best is trial 4 with value: 0.8978102189781021.\n",
      "[I 2024-12-04 16:28:39,422] Trial 7 finished with value: 0.8896999188969993 and parameters: {'hidden_layer_sizes': 50, 'alpha': 0.0002582154488440205}. Best is trial 4 with value: 0.8978102189781021.\n",
      "[I 2024-12-04 16:32:22,942] Trial 8 finished with value: 0.8910786699107867 and parameters: {'hidden_layer_sizes': 50, 'alpha': 0.004614145900183355}. Best is trial 4 with value: 0.8978102189781021.\n",
      "[I 2024-12-04 16:35:51,514] Trial 9 finished with value: 0.8875912408759123 and parameters: {'hidden_layer_sizes': 150, 'alpha': 0.03840569553854208}. Best is trial 4 with value: 0.8978102189781021.\n",
      "[I 2024-12-04 16:37:49,468] Trial 10 finished with value: 0.8980535279805352 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.09472940738342005}. Best is trial 10 with value: 0.8980535279805352.\n",
      "[I 2024-12-04 16:40:00,060] Trial 11 finished with value: 0.8993511759935118 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.09765123342753287}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:42:16,666] Trial 12 finished with value: 0.8989456609894567 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.09411520834999286}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:44:36,943] Trial 13 finished with value: 0.8922141119221412 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.029913438534208837}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:46:25,026] Trial 14 finished with value: 0.8872668288726683 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.012621388656986565}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:48:22,504] Trial 15 finished with value: 0.8848337388483374 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.0012776047315799554}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:50:07,413] Trial 16 finished with value: 0.8844282238442822 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.015875679350932436}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:51:12,639] Trial 17 finished with value: 0.8927818329278183 and parameters: {'hidden_layer_sizes': 150, 'alpha': 0.05458902319993839}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:53:04,837] Trial 18 finished with value: 0.8838605028386051 and parameters: {'hidden_layer_sizes': 100, 'alpha': 0.0016421605101974688}. Best is trial 11 with value: 0.8993511759935118.\n",
      "[I 2024-12-04 16:54:50,753] Trial 19 finished with value: 0.8841849148418491 and parameters: {'hidden_layer_sizes': 150, 'alpha': 0.01952454561916255}. Best is trial 11 with value: 0.8993511759935118.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Results:\n",
      "Random Forest Best Accuracy: 0.9045\n",
      "Logistic Regression Best Accuracy: 0.8844\n",
      "SVM Best Accuracy: 0.8947\n",
      "MLP Classifier Best Accuracy: 0.8994\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the data\n",
    "    df = load_data()\n",
    "\n",
    "    # Preprocess the data\n",
    "    X, y, preprocessor = preprocess_data(df)\n",
    "    print('\\n--------------------------------------------------------------------------------\\n')    \n",
    "    # Evaluate before optimization\n",
    "    print(\"Evaluating models before optimization...\\n\")\n",
    "    models = {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "        \"Support Vector Machine\": SVC(kernel=\"rbf\", random_state=42),\n",
    "        \"MLP Classifier\": MLPClassifier(max_iter=500, random_state=42)\n",
    "    }\n",
    "    for model_name, model in models.items():\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "        print(f\"{model_name} Accuracy: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")\n",
    "        \n",
    "    print('\\n--------------------------------------------------------------------------------\\n')    \n",
    "\n",
    "    # Optimize models using Optuna\n",
    "    \n",
    "    print(\"\\nOptimizing models using Optuna...\\n\")\n",
    "    study_rf = optuna.create_study(direction=\"maximize\")\n",
    "    study_rf.optimize(lambda trial: optimize_random_forest(trial, X, y, preprocessor), n_trials=20)\n",
    "\n",
    "    study_lr = optuna.create_study(direction=\"maximize\")\n",
    "    study_lr.optimize(lambda trial: optimize_logistic_regression(trial, X, y, preprocessor), n_trials=20)\n",
    "\n",
    "    study_svm = optuna.create_study(direction=\"maximize\")\n",
    "    study_svm.optimize(lambda trial: optimize_svm(trial, X, y, preprocessor), n_trials=20)\n",
    "\n",
    "    study_mlp = optuna.create_study(direction=\"maximize\")\n",
    "    study_mlp.optimize(lambda trial: optimize_mlp(trial, X, y, preprocessor), n_trials=20)\n",
    "\n",
    "    # Print optimized results\n",
    "    print(\"\\nOptimized Results:\\n\")\n",
    "    print(f\"Random Forest Best Accuracy: {study_rf.best_value:.4f}\")\n",
    "    print(f\"Logistic Regression Best Accuracy: {study_lr.best_value:.4f}\")\n",
    "    print(f\"SVM Best Accuracy: {study_svm.best_value:.4f}\")\n",
    "    print(f\"MLP Classifier Best Accuracy: {study_mlp.best_value:.4f}\")\n",
    "   \n",
    "    print('\\n--------------------------------------------------------------------------------\\n')    \n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c052148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running models with user-defined parameters...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Please enter the parameters\n",
      "Enter the number of estimators for Random Forest (e.g 100): 400\n",
      "Enter the max iterations for Logistic Regression (e.g., 200): 100\n",
      "Enter the kernel for SVM (e.g., 'linear', 'rbf'): rbf\n",
      "Enter the hidden layer size for MLP (e.g., 100): 200\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Accuracy with User Parameters: 0.9030 (+/- 0.0035)\n",
      "Logistic Regression Accuracy with User Parameters: 0.8843 (+/- 0.0036)\n",
      "Support Vector Machine Accuracy with User Parameters: 0.8932 (+/- 0.0053)\n",
      "MLP Classifier Accuracy with User Parameters: 0.8807 (+/- 0.0061)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# user Inputs\n",
    "\n",
    "def main():        \n",
    "    # Load the data\n",
    "    df = load_data()\n",
    "\n",
    "    # Preprocess the data\n",
    "    X, y, preprocessor = preprocess_data(df)\n",
    "    # Run models with user-defined parameters\n",
    "    print(\"\\nRunning models with user-defined parameters...\")\n",
    "    print('\\n--------------------------------------------------------------------------------\\n')\n",
    "    print('\\n Please enter the parameters')\n",
    "    rf_n_estimators = int(input(\"Enter the number of estimators for Random Forest (e.g 100): \"))\n",
    "    lr_max_iter = int(input(\"Enter the max iterations for Logistic Regression (e.g., 200): \"))\n",
    "    svm_kernel = input(\"Enter the kernel for SVM (e.g., 'linear', 'rbf'): \")\n",
    "    mlp_hidden_layer_sizes = int(input(\"Enter the hidden layer size for MLP (e.g., 100): \"))\n",
    "    print('\\n\\n')\n",
    "\n",
    "    user_models = {\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=rf_n_estimators, random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=lr_max_iter, random_state=42),\n",
    "        \"Support Vector Machine\": SVC(kernel=svm_kernel, random_state=42),\n",
    "        \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(mlp_hidden_layer_sizes,), max_iter=500, random_state=42)\n",
    "    }\n",
    "    for model_name, model in user_models.items():\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "        print(f\"{model_name} Accuracy with User Parameters: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")\n",
    "        \n",
    "    print('\\n--------------------------------------------------------------------------------\\n')\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d6fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
